<?xml version="1.0" encoding="UTF-8"?>



<configuration>
    <appender name="STDOUT" class="ch.qos.logback.core.ConsoleAppender">
        <encoder>
            <pattern>%date{[yyyy-MM-dd] HH:mm:ss.SSS} demo-%X{traceId} [%thread]-[%file:%line]-[%level] %msg%n
            </pattern>
        </encoder>
    </appender>

    <appender name="remark" class="ch.qos.logback.core.ConsoleAppender">
        <encoder>
            <pattern>remkk-[%level] %msg%n
            </pattern>
        </encoder>
    </appender>

    <!-- 每天产生一个文件 -->
    <appender name="file" class="ch.qos.logback.core.rolling.RollingFileAppender">
        <!-- 文件路径 -->
        <rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy">
            <!-- 文件名称 -->
            <fileNamePattern>/Users/admin/Downloads/test01/demo-api.%d{yyyy-MM-dd}.log</fileNamePattern>
            <!-- 文件最大保存历史数量 -->
            <MaxHistory>100</MaxHistory>
        </rollingPolicy>
        <layout class="ch.qos.logback.classic.PatternLayout">
            <pattern>demoFile-%X{traceId} [%thread]-[%file:%line]-[%level] %msg%n</pattern>
        </layout>
    </appender>

    <!-- This is the kafkaAppender -->
    <appender name="kafkaAppender" class="com.github.danielwegener.logback.kafka.KafkaAppender">
        <encoder>
            <pattern>kafka-[%thread] %-5level %logger{36} - %msg%n</pattern>
        </encoder>

        <topic>operationLog</topic>
        <keyingStrategy class="com.github.danielwegener.logback.kafka.keying.NoKeyKeyingStrategy" />
        <deliveryStrategy class="com.github.danielwegener.logback.kafka.delivery.AsynchronousDeliveryStrategy" />

        <producerConfig>bootstrap.servers=127.0.0.1:9093</producerConfig>
        <!--<producerConfig>security.protocol=SASL_PLAINTEXT</producerConfig>
        <producerConfig>sasl.kerberos.service.name=kafka</producerConfig>
        <producerConfig>sasl.mechanism=GSSAPI</producerConfig>-->
        <producerConfig>acks=1</producerConfig>
        <producerConfig>client.id=CCS-test</producerConfig>
        <producerConfig>request.timeout.ms=6000</producerConfig>
        <producerConfig>retries=1</producerConfig>
        <producerConfig>metadata.fetch.timeout.ms=9</producerConfig>
        <!-- this is the fallback appender if kafka is not available. -->
        <appender-ref ref="file" />
    </appender>

    <logger name="org.springframework" level="ERROR"/>
    <logger name="org.springframework.web.servlet.DispatcherServlet" level="ERROR"/>
    <logger name="org.apache.commons" level="INFO"/>
    <logger name="org.springframework.web.context.support.XmlWebApplicationContext" level="ERROR"/>
    <logger name="org.springframework.web.servlet.handler.SimpleUrlHandlerMapping" level="ERROR"/>
    <logger name="rg.apache.catalina.core.ContainerBase" level="INFO"/>

    <root level="INFO">
        <appender-ref ref="kafkaAppender"/>
        <appender-ref ref="STDOUT"/>
    </root>
</configuration>